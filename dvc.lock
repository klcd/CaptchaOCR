schema: '2.0'
stages:
  split_data:
    cmd: python src/stages/split.py --config params.yaml
    deps:
    - path: data/raw
      md5: 0715df1127d114a15a3b9b853a03c283.dir
      size: 8973240
      nfiles: 1070
    params:
      params.yaml:
        base:
          random_seed: 98723
          image_width: 200
          image_height: 50
        split:
          train_fraction: 0.9
          shuffle: true
          input_dir: data/raw
          output_dir: data/split
          outputs:
            max_length: data/split/maxlength.txt
            characters: data/split/characterset.txt
            x_train: data/split/x_train.txt
            y_train: data/split/y_train.txt
            x_valid: data/split/x_valid.txt
            y_valid: data/split/y_valid.txt
    outs:
    - path: data/split/characterset.txt
      md5: 6aeac9565ac14d35602fdf95dc8bed1b
      size: 38
    - path: data/split/x_train.txt
      md5: 35b156723b23428f246aeff1f8e7bfb5
      size: 17784
    - path: data/split/x_valid.txt
      md5: 6c8829dda5b5ea8c6bcdb14626e1769e
      size: 1976
    - path: data/split/y_train.txt
      md5: 11cabd50b614010a5e589fad81580af3
      size: 5616
    - path: data/split/y_valid.txt
      md5: b237032f121ede08f4ff8815d1a2dee8
      size: 624
  create_datasets:
    cmd: python src/stages/datasets.py --config params.yaml
    deps:
    - path: data/split/x_train.txt
      md5: 35b156723b23428f246aeff1f8e7bfb5
      size: 17784
    - path: data/split/x_valid.txt
      md5: 6c8829dda5b5ea8c6bcdb14626e1769e
      size: 1976
    - path: data/split/y_train.txt
      md5: 11cabd50b614010a5e589fad81580af3
      size: 5616
    - path: data/split/y_valid.txt
      md5: b237032f121ede08f4ff8815d1a2dee8
      size: 624
    params:
      params.yaml:
        base:
          random_seed: 98723
          image_width: 200
          image_height: 50
        transform:
          batch_size: 16
          inputs:
            characters: data/split/characterset.txt
            x_train: data/split/x_train.txt
            y_train: data/split/y_train.txt
            x_valid: data/split/x_valid.txt
            y_valid: data/split/y_valid.txt
          outputs:
            train_dataset: data/datasets/train_dataset
            valid_dataset: data/datasets/validation_dataset
            sample_plot: plots/sample_plot.png
    outs:
    - path: data/datasets/train_dataset
      md5: 4bf666dc25beda6177fd8682d3cba64b.dir
      size: 37481729
      nfiles: 2
    - path: data/datasets/validation_dataset
      md5: 11ebb53c2c6718595253309ed0614b75.dir
      size: 4164706
      nfiles: 2
  model_setup:
    cmd: python src/stages/model_setup.py --config params.yaml
    deps:
    - path: data/split/characterset.txt
      md5: 6aeac9565ac14d35602fdf95dc8bed1b
      size: 38
    params:
      params.yaml:
        base:
          random_seed: 98723
          image_width: 200
          image_height: 50
        model_setup:
          inputs:
            characters: data/split/characterset.txt
          outputs:
            untrained_model: models/untrained_model.h5
          model_name: ocr_model1
          optimizer: keras.optimizers.Adam()
          layer_params:
            conv1:
              name: conv1
              filters: 32
              kernel_size:
              - 3
              - 3
              activation: relu
              kernel_initializer: he_normal
              padding: same
            max_pooling1:
              name: pool1
              pool_size:
              - 2
              - 2
            conv2:
              name: conv2
              filters: 64
              kernel_size:
              - 3
              - 3
              activation: relu
              kernel_initializer: he_normal
              padding: same
            max_pooling2:
              name: pool2
              pool_size:
              - 2
              - 2
            reshape:
              name: reshape
            dense1:
              name: dense1
              units: 64
              activation: relu
            dropout1:
              name: dropout1
              rate: 0.2
            bidirec_lstm1:
              name: bidirec_lstm1
              units: 128
              return_sequences: true
              dropout: 0.25
            bidirec_lstm2:
              name: bidirec_lstm2
              units: 64
              return_sequences: true
              dropout: 0.25
            dense2:
              name: dense2
              activation: softmax
    outs:
    - path: models/untrained_model.h5
      md5: d7f6e32ad2765f85befaabb4e245ccc4
      size: 1776088
  training:
    cmd: python src/stages/training.py --config params.yaml
    deps:
    - path: data/datasets/train_dataset
      md5: 88ac6166daa71d254d870e1559836ac8.dir
      size: 74963417
      nfiles: 3
    - path: data/datasets/validation_dataset
      md5: b457965d93eea5c845b9cfde0bce5178.dir
      size: 8329369
      nfiles: 3
    - path: models/untrained_model.h5
      md5: d7f6e32ad2765f85befaabb4e245ccc4
      size: 1776088
    params:
      params.yaml:
        base:
          random_seed: 98723
          image_width: 200
          image_height: 50
        train:
          inputs:
            model: models/untrained_model.h5
            train_data: data/datasets/train_dataset
            validation_data: data/datasets/validation_dataset
          outputs:
            model: models/trained_model.h5
            prediction_model: models/prediction_model.h5
            history_plot: plots/training_history.png
            tensorboard: training_log
          early_stopping:
            patience: 5
            restore_best_weights: true
            monitor: val_loss
          fit:
            epochs: 2
    outs:
    - path: models/prediction_model.h5
      md5: e7efdcc39d72830b929677c8b4442a05
      size: 1773984
    - path: models/trained_model.h5
      md5: b811390a3b4f0e47775f308a67c1b2ad
      size: 5290536
